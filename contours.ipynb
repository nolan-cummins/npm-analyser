{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab6341a-5775-45db-a01a-8634495dadaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T00:39:29.712539Z",
     "iopub.status.busy": "2023-08-22T00:39:29.712539Z",
     "iopub.status.idle": "2023-08-22T00:39:29.722564Z",
     "shell.execute_reply": "2023-08-22T00:39:29.722064Z",
     "shell.execute_reply.started": "2023-08-22T00:39:29.712539Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 objects were found in this image.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"images/1.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "brightened = cv2.addWeighted(gray, 1.15, np.zeros(gray.shape, gray.dtype), 0, 25)\n",
    "blurred = cv2.bilateralFilter(brightened, 9, 100, 100)\n",
    "cv2.imshow(\"blurred\", blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "edged = cv2.Canny(blurred, 20, 25, L2gradient=True)\n",
    "\n",
    "# define a (3, 3) structuring element\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "# apply the dilation operation to the edged image\n",
    "dilate = cv2.dilate(edged, kernel, iterations=1)\n",
    "cv2.imshow(\"Dilated image\", dilate)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# find the contours in the dilated image\n",
    "contours, _ = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "image_copy = image.copy()\n",
    "# draw the contours on a copy of the original image\n",
    "cv2.drawContours(image_copy, contours, -1, (0, 255, 0), 2)\n",
    "print(len(contours), \"objects were found in this image.\")\n",
    "\n",
    "cv2.imshow(\"contours\", image_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 objects were found in this image.\n",
      "217 objects were found in this image.\n",
      "189 objects were found in this image.\n",
      "216 objects were found in this image.\n",
      "204 objects were found in this image.\n",
      "192 objects were found in this image.\n",
      "219 objects were found in this image.\n",
      "193 objects were found in this image.\n",
      "203 objects were found in this image.\n",
      "196 objects were found in this image.\n",
      "203 objects were found in this image.\n",
      "218 objects were found in this image.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m img \u001b[39m=\u001b[39m frame\n\u001b[0;32m     45\u001b[0m height, width \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m---> 46\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((height, width), np\u001b[39m.\u001b[39muint8) \u001b[39m*\u001b[39m \u001b[39m128\u001b[39m\n\u001b[0;32m     47\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((height, width), np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     48\u001b[0m \u001b[39m# generating the kernels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nolan\\anaconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:206\u001b[0m, in \u001b[0;36mones\u001b[1;34m(shape, dtype, order, like)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[39mreturn\u001b[39;00m _ones_with_like(shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[0;32m    205\u001b[0m a \u001b[39m=\u001b[39m empty(shape, dtype, order)\n\u001b[1;32m--> 206\u001b[0m multiarray\u001b[39m.\u001b[39mcopyto(a, \u001b[39m1\u001b[39m, casting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcopyto\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('videos/1.avi')\n",
    "# get the video frame height and width\n",
    "#frame_width = int(cap.get(3))\n",
    "#frame_height = int(cap.get(4))\n",
    "#save_name = f\"videos/1_output.mp4\"\n",
    "# define codec and create VideoWriter object\n",
    "#out = cv2.VideoWriter(\n",
    "#    save_name,\n",
    "#    cv2.VideoWriter_fourcc(*'mp4v'), 10, \n",
    "#    (frame_width, frame_height)\n",
    "#)\n",
    "# Flag to indicate if the video is paused\n",
    "paused = False\n",
    "\n",
    "# Loop until explicitly stopped\n",
    "while True:\n",
    "    # Pause or resume video playback\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(' '):  # Spacebar key\n",
    "        paused = not paused\n",
    "\n",
    "    # Exit the loop when 'q' key is pressed\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "    if paused:\n",
    "        continue\n",
    "    # Check if the video capture has reached the end\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        # Reset video capture to restart the loop\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if frame was successfully captured\n",
    "    if not ret:\n",
    "        break      \n",
    "\n",
    "    img = frame\n",
    "    height, width = img.shape[:2]\n",
    "    y = np.ones((height, width), np.uint8) * 128\n",
    "    output = np.zeros((height, width), np.uint8)\n",
    "    # generating the kernels\n",
    "    kernel1 = np.array([[0, -1, -1], # kernel for embossing bottom left side\n",
    "                        [1, 0, -1],\n",
    "                        [1, 1, 0]])\n",
    "    kernel2 = np.array([[-1, -1, 0], # kernel for embossing bottom right side\n",
    "                        [-1, 0, 1],\n",
    "                        [0, 1, 1]])\n",
    "    # you can generate kernels for embossing top as well\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    output1 = cv2.add(cv2.filter2D(gray, -1, kernel1), y) # emboss on bottom left side\n",
    "    output2 = cv2.add(cv2.filter2D(gray, -1, kernel2), y) # emboss on bottom right side\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            output[i, j] = max(output1[i, j], output2[i, j]) # combining both embosses to produce stronger emboss\n",
    "\n",
    "    brightened = cv2.addWeighted(output, 1.15, np.zeros(gray.shape, gray.dtype), 0, 25)\n",
    "    blurred = cv2.bilateralFilter(brightened, 9, 100, 100)\n",
    "\n",
    "\n",
    "    edged = cv2.Canny(blurred, 20, 25, L2gradient=True)\n",
    "\n",
    "    # define a (3, 3) structuring element\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # apply the dilation operation to the edged image\n",
    "    dilate = cv2.dilate(edged, kernel, iterations=1)\n",
    "\n",
    "    # find the contours in the dilated image\n",
    "    contours, _ = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_copy = img.copy()\n",
    "    # draw the contours on a copy of the original image\n",
    "    cv2.drawContours(image_copy, contours, -1, (0, 255, 0), 2)\n",
    "    print(len(contours), \"objects were found in this image.\")\n",
    "\n",
    "    #cv2.imshow(\"final\", image_copy)\n",
    "    #out.write(image_copy)\n",
    "    #if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "\n",
    "    # save each frame as a .jpg image\n",
    "    count = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    cv2.imwrite(f\"images/{count}.jpg\", image_copy)\n",
    "    count += 1\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
